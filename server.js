// server.js
require('dotenv').config();
const express = require('express');
const fetch = require('node-fetch');
const path = require('path');

const app = express();
const PORT = process.env.PORT || 3000;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

// Serve static frontend from 'public' folder
app.use(express.static(path.join(__dirname, 'public')));
app.use(express.json());

// API route to securely proxy OpenAI calls
app.post('/api/scholarships', async (req, res) => {
  const { prompt } = req.body;
  try {
    const response = await fetch('https://api.openai.com/v1/engines/davinci/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        prompt,
        max_tokens: 200,
        temperature: 0.7,
        n: 1
      })
    });
    const data = await response.json();
    res.json(data);
  } catch (error) {
    console.error('OpenAI API error:', error);
    res.status(500).json({ error: 'Something went wrong with the AI request.' });
  }
});

app.listen(PORT, () => {
  console.log(`âœ… Server running at http://localhost:${PORT}`);
});
